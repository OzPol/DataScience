{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Price Prediction Analysis\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook aims to analyze the Ames Housing dataset and build predictive models for housing prices. The notebook is organized into several sections, each focusing on a different aspect of the data analysis and modeling process. The primary goal is to provide a comprehensive understanding of the factors influencing house prices and to develop robust predictive models.\n",
    "\n",
    "### Exploratory Data Analysis\n",
    "-   **Get to know the data & Basic Statistics**\n",
    "\n",
    "### Data Preparation\n",
    "Data preparation involves handling missing values, encoding categorical variables, and selecting relevant features for modeling.\n",
    "\n",
    "1. **Handling Missing Values**: Missing data is imputed using appropriate strategies to ensure completeness of the dataset.\n",
    "2. **Encoding Categorical Variables**: Categorical variables are encoded using one-hot encoding to make them suitable for modeling.\n",
    "3. **Feature Selection**: Relevant features are selected based on their importance and correlation with the target variable, SalePrice.\n",
    "\n",
    "### Univariate Analysis\n",
    "Univariate analysis focuses on the distribution and characteristics of individual variables.\n",
    "\n",
    "1. **Histograms**: Histograms are used to visualize the distribution of numerical features.\n",
    "2. **Box Plots**: Box plots are used to identify outliers and understand the spread of numerical features.\n",
    "\n",
    "### Bivariate Analysis\n",
    "Bivariate analysis explores the relationships between pairs of variables.\n",
    "\n",
    "1. **Correlation Heatmap**: A heatmap of the correlation matrix is used to identify strong relationships between features and the target variable.\n",
    "2. **Scatter Plots**: Scatter plots are used to visualize the relationships between selected features and SalePrice.\n",
    "\n",
    "### Multivariate Analysis\n",
    "Multivariate analysis examines the relationships between multiple variables simultaneously to identify patterns and interactions that may not be evident in univariate or bivariate analyses.\n",
    "\n",
    "### Baseline Linear Regression Models\n",
    "Baseline linear regression models are built to understand the linear relationships between selected features and SalePrice.\n",
    "\n",
    "### Advanced Regression Analysis\n",
    "Advanced regression techniques are employed to improve the predictive performance of the models.\n",
    "\n",
    "1. **Ridge Regression**: A regularized regression technique to handle multicollinearity and prevent overfitting.\n",
    "2. **Lasso Regression**: Another regularized regression technique that performs feature selection by shrinking some coefficients to zero.\n",
    "3. **ElasticNet Regression**: A combination of Ridge and Lasso regression that balances their strengths.\n",
    "\n",
    "### Model Training and Validation\n",
    "Various machine learning models are trained and validated to predict housing prices.\n",
    "\n",
    "1. **Support Vector Regression (SVR)**: A robust regression technique that aims to minimize prediction errors.\n",
    "2. **Artificial Neural Networks (ANN)**: A deep learning approach that captures complex patterns in the data.\n",
    "3. **XGBoost**: An ensemble learning method that builds multiple weak learners to create a strong predictive model.\n",
    "\n",
    "### Ensemble Modeling\n",
    "Ensemble modeling combines multiple models to improve overall prediction accuracy.\n",
    "\n",
    "1. **Stacking Models**: Different models are stacked to leverage their individual strengths.\n",
    "2. **Blending Models**: Predictions from multiple models are blended to achieve better performance.\n",
    "\n",
    "### Prediction\n",
    "The final models are used to make predictions on the test data, and the results are evaluated to determine the best-performing model.\n",
    "\n",
    "## Goals\n",
    "- **Identify Key Features**: Determine the most important features influencing housing prices.\n",
    "- **Build Robust Models**: Develop and validate different regression models to accurately predict housing prices.\n",
    "- **Improve Predictive Accuracy**: Use advanced techniques and ensemble methods to enhance the performance of the predictive models.\n",
    "\n",
    "This analysis will provide insights into the factors affecting housing prices in Ames and demonstrate the application of various machine learning techniques to build effective predictive models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from keras import layers\n",
    "from keras import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ames dataset\n",
    "file_path = '../data/AmesData.csv'\n",
    "ames_df = pd.read_csv(file_path)\n",
    "\n",
    "# Specifically replace blanks in 'MasVnrArea' with 0\n",
    "ames_df.replace({'MasVnrArea': 'nan'}, 0, inplace=True)\n",
    "\n",
    "# Identify columns with missing values\n",
    "missing_values = ames_df.isnull().sum()\n",
    "missing_cols = missing_values[missing_values > 0].index.tolist()\n",
    "\n",
    "# Separate numerical and categorical columns with missing values\n",
    "num_cols_with_missing = ames_df.select_dtypes(include=[np.number]).columns[ames_df.select_dtypes(include=[np.number]).isnull().any()].tolist()\n",
    "cat_cols_with_missing = ames_df.select_dtypes(exclude=[np.number]).columns[ames_df.select_dtypes(exclude=[np.number]).isnull().any()].tolist()\n",
    "\n",
    "# Handle missing values for numerical columns\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "ames_df[num_cols_with_missing] = num_imputer.fit_transform(ames_df[num_cols_with_missing])\n",
    "\n",
    "# Handle missing values for categorical columns\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "ames_df[cat_cols_with_missing] = cat_imputer.fit_transform(ames_df[cat_cols_with_missing])\n",
    "\n",
    "# Ensure no missing values remain\n",
    "print(\"\\nColumns with missing values after imputation and their counts:\")\n",
    "print(ames_df.isnull().sum()[ames_df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standardize 'SalePrice'\n",
    "saleprice_scaled = StandardScaler().fit_transform(ames_df['SalePrice'].values.reshape(-1, 1))\n",
    "plt.show()\n",
    "\n",
    "# Remove outliers based on 'GrLivArea'\n",
    "ames_df.sort_values(by='GrLivArea', ascending=False)[:2]\n",
    "ames_df = ames_df.drop(ames_df[ames_df['GrLivArea'] > 4000].index)\n",
    "\n",
    "# Plot scatter plot for 'TotalBsmtSF' vs 'SalePrice'\n",
    "var = 'TotalBsmtSF'\n",
    "data = pd.concat([ames_df['SalePrice'], ames_df[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='SalePrice', color = 'green', ylim=(0, 800000))\n",
    "plt.title('Scatter plot of TotalBsmtSF vs SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the Ames dataset:\n",
      "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0          20       RL           78    10140   Pave  Grvl      Reg   \n",
      "1          20       RL           88    12803   Pave  Grvl      IR1   \n",
      "2          60       RL           86    11839   Pave  Grvl      Reg   \n",
      "3          90       RL           75     8235   Pave  Grvl      Reg   \n",
      "4          20       RL           60     9060   Pave  Grvl      Reg   \n",
      "\n",
      "  LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
      "0         Lvl    AllPub    Inside  ...      648     Fa  GdPrv        Shed   \n",
      "1         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "2         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "3         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "4         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "\n",
      "  MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0       0      1    2006        WD         Normal     181000  \n",
      "1       0      9    2008        WD         Normal     221000  \n",
      "2       0      5    2008        WD         Normal     262280  \n",
      "3       0      5    2006        WD         Normal     157000  \n",
      "4       0      6    2007        WD         Normal     120000  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "\n",
      "Summary statistics of the Ames dataset:\n",
      "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
      "count  2764.000000  2764.000000    2764.000000  2764.000000  2764.000000   \n",
      "mean     56.318741    57.511939   10228.543777     6.173300     5.571274   \n",
      "std      41.363252    33.447928    7914.670733     1.372391     1.069594   \n",
      "min      20.000000     0.000000    1300.000000     1.000000     1.000000   \n",
      "25%      20.000000    42.000000    7530.750000     5.000000     5.000000   \n",
      "50%      50.000000    63.000000    9547.500000     6.000000     5.000000   \n",
      "75%      70.000000    79.000000   11643.500000     7.000000     6.000000   \n",
      "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
      "\n",
      "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\n",
      "count  2764.000000   2764.000000  2764.000000  2764.000000  2764.000000  ...   \n",
      "mean   1972.888567   1984.802822   104.852388   450.636758    51.971056  ...   \n",
      "std      29.435267     20.623677   178.913621   439.735716   173.053532  ...   \n",
      "min    1879.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n",
      "25%    1955.000000   1966.000000     0.000000     0.000000     0.000000  ...   \n",
      "50%    1976.000000   1993.000000     0.000000   385.000000     0.000000  ...   \n",
      "75%    2001.000000   2004.000000   170.000000   745.000000     0.000000  ...   \n",
      "max    2010.000000   2010.000000  1600.000000  2288.000000  1526.000000  ...   \n",
      "\n",
      "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
      "count  2764.000000  2764.000000    2764.000000  2764.000000  2764.000000   \n",
      "mean     96.824168    47.666425      22.085022     2.684515    16.844428   \n",
      "std     127.549399    64.874194      63.622123    25.666497    57.471871   \n",
      "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "50%       0.000000    28.000000       0.000000     0.000000     0.000000   \n",
      "75%     169.000000    72.000000       0.000000     0.000000     0.000000   \n",
      "max    1424.000000   570.000000    1012.000000   508.000000   576.000000   \n",
      "\n",
      "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
      "count  2764.000000   2764.000000  2764.000000  2764.000000    2764.000000  \n",
      "mean      2.003618     43.885311     6.229740  2007.787988  184714.983357  \n",
      "std      33.907829    478.270120     2.705413     1.316638   78196.400433  \n",
      "min       0.000000      0.000000     1.000000  2006.000000   12789.000000  \n",
      "25%       0.000000      0.000000     4.000000  2007.000000  132875.000000  \n",
      "50%       0.000000      0.000000     6.000000  2008.000000  165000.000000  \n",
      "75%       0.000000      0.000000     8.000000  2009.000000  217000.000000  \n",
      "max     800.000000  15500.000000    12.000000  2010.000000  625000.000000  \n",
      "\n",
      "[8 rows x 37 columns]\n",
      "\n",
      "Column names of the Ames dataset:\n",
      "['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice']\n",
      "\n",
      "First few rows of the training set:\n",
      "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "2755          20       RL           68     8298   Pave  Grvl      IR1   \n",
      "1853          20       RM           50     6000   Pave  Grvl      Reg   \n",
      "653           20       FV           75     7500   Pave  Grvl      Reg   \n",
      "263           60       RL           80     9200   Pave  Grvl      Reg   \n",
      "1257         160       RL           44     5306   Pave  Grvl      IR1   \n",
      "\n",
      "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
      "2755         HLS    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "1853         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "653          Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "263          Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "1257         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "\n",
      "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "2755       0      9    2007       New        Partial     267300  \n",
      "1853       0      6    2008        WD         Normal     112500  \n",
      "653        0      6    2009        WD         Normal     238500  \n",
      "263        0      6    2008        WD         Normal     315000  \n",
      "1257       0      6    2006        WD         Normal     239000  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "\n",
      "First few rows of the testing set:\n",
      "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "1992          50  C (all)           60     7500   Pave  Grvl      Reg   \n",
      "1220         120       RM           35     3907   Pave  Grvl      IR1   \n",
      "1389          20       RL            0    15611   Pave  Grvl      IR1   \n",
      "2567          70       RM           57     9639   Pave  Grvl      Reg   \n",
      "1338          20       FV           72     8640   Pave  Grvl      Reg   \n",
      "\n",
      "     LandContour Utilities LotConfig  ... PoolArea PoolQC  Fence MiscFeature  \\\n",
      "1992         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "1220         HLS    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "1389         Lvl    AllPub    Corner  ...        0     Ex  MnPrv        Shed   \n",
      "2567         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "1338         Lvl    AllPub    Inside  ...        0     Ex  MnPrv        Shed   \n",
      "\n",
      "     MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "1992       0      4    2010       COD        Abnorml      68400  \n",
      "1220       0      4    2010        WD         Normal     185000  \n",
      "1389       0      3    2008        WD        Abnorml     175000  \n",
      "2567       0      5    2007        WD         Normal     137000  \n",
      "1338       0     11    2007       New        Partial     208900  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the Ames dataset\n",
    "print(\"First few rows of the Ames dataset:\")\n",
    "print(ames_df.head())\n",
    "\n",
    "# Display summary statistics of the Ames dataset\n",
    "print(\"\\nSummary statistics of the Ames dataset:\")\n",
    "print(ames_df.describe())\n",
    "\n",
    "# List the column names of the Ames dataset\n",
    "print(\"\\nColumn names of the Ames dataset:\")\n",
    "print(ames_df.columns.tolist())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df, test_df = train_test_split(ames_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first few rows of the training set\n",
    "print(\"\\nFirst few rows of the training set:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Display the first few rows of the testing set\n",
    "print(\"\\nFirst few rows of the testing set:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.00000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.00000</td>\n",
       "      <td>2211.000000</td>\n",
       "      <td>2211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.180461</td>\n",
       "      <td>57.832203</td>\n",
       "      <td>10277.734962</td>\n",
       "      <td>6.184080</td>\n",
       "      <td>5.57033</td>\n",
       "      <td>1972.789688</td>\n",
       "      <td>1984.802352</td>\n",
       "      <td>104.818634</td>\n",
       "      <td>451.950249</td>\n",
       "      <td>53.603799</td>\n",
       "      <td>...</td>\n",
       "      <td>96.873360</td>\n",
       "      <td>48.305744</td>\n",
       "      <td>22.127092</td>\n",
       "      <td>2.482587</td>\n",
       "      <td>17.637268</td>\n",
       "      <td>2.208051</td>\n",
       "      <td>45.781999</td>\n",
       "      <td>6.25735</td>\n",
       "      <td>2007.789688</td>\n",
       "      <td>185201.412483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.981284</td>\n",
       "      <td>33.454181</td>\n",
       "      <td>8379.516457</td>\n",
       "      <td>1.365721</td>\n",
       "      <td>1.06440</td>\n",
       "      <td>29.457809</td>\n",
       "      <td>20.562746</td>\n",
       "      <td>178.869930</td>\n",
       "      <td>441.751781</td>\n",
       "      <td>176.533133</td>\n",
       "      <td>...</td>\n",
       "      <td>128.063934</td>\n",
       "      <td>65.945732</td>\n",
       "      <td>64.150640</td>\n",
       "      <td>24.286004</td>\n",
       "      <td>59.229514</td>\n",
       "      <td>36.188110</td>\n",
       "      <td>462.162916</td>\n",
       "      <td>2.69645</td>\n",
       "      <td>1.321114</td>\n",
       "      <td>78282.866386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1880.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>7586.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1955.000000</td>\n",
       "      <td>1966.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>132000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>9550.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>167000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>11645.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>755.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>169.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>217150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>2288.000000</td>\n",
       "      <td>1526.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>625000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  2211.000000  2211.000000    2211.000000  2211.000000   2211.00000   \n",
       "mean     56.180461    57.832203   10277.734962     6.184080      5.57033   \n",
       "std      40.981284    33.454181    8379.516457     1.365721      1.06440   \n",
       "min      20.000000     0.000000    1300.000000     1.000000      1.00000   \n",
       "25%      20.000000    43.000000    7586.500000     5.000000      5.00000   \n",
       "50%      50.000000    63.000000    9550.000000     6.000000      5.00000   \n",
       "75%      70.000000    79.000000   11645.000000     7.000000      6.00000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000      9.00000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\n",
       "count  2211.000000   2211.000000  2211.000000  2211.000000  2211.000000  ...   \n",
       "mean   1972.789688   1984.802352   104.818634   451.950249    53.603799  ...   \n",
       "std      29.457809     20.562746   178.869930   441.751781   176.533133  ...   \n",
       "min    1880.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%    1955.000000   1966.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%    1975.000000   1993.000000     0.000000   381.000000     0.000000  ...   \n",
       "75%    2002.000000   2004.000000   171.000000   755.500000     0.000000  ...   \n",
       "max    2010.000000   2010.000000  1600.000000  2288.000000  1526.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  2211.000000  2211.000000    2211.000000  2211.000000  2211.000000   \n",
       "mean     96.873360    48.305744      22.127092     2.482587    17.637268   \n",
       "std     128.063934    65.945732      64.150640    24.286004    59.229514   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    28.000000       0.000000     0.000000     0.000000   \n",
       "75%     169.500000    72.500000       0.000000     0.000000     0.000000   \n",
       "max    1424.000000   570.000000    1012.000000   508.000000   576.000000   \n",
       "\n",
       "          PoolArea       MiscVal      MoSold       YrSold      SalePrice  \n",
       "count  2211.000000   2211.000000  2211.00000  2211.000000    2211.000000  \n",
       "mean      2.208051     45.781999     6.25735  2007.789688  185201.412483  \n",
       "std      36.188110    462.162916     2.69645     1.321114   78282.866386  \n",
       "min       0.000000      0.000000     1.00000  2006.000000   12789.000000  \n",
       "25%       0.000000      0.000000     4.00000  2007.000000  132000.000000  \n",
       "50%       0.000000      0.000000     6.00000  2008.000000  167000.000000  \n",
       "75%       0.000000      0.000000     8.00000  2009.000000  217150.000000  \n",
       "max     800.000000  15500.000000    12.00000  2010.000000  625000.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 2764 rows and 80 columns.\n"
     ]
    }
   ],
   "source": [
    "# Get the number of rows and columns in the Ames dataset\n",
    "num_rows, num_columns = ames_df.shape\n",
    "\n",
    "print(f\"The dataset contains {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of the Ames dataset:\n",
      "['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the Ames dataset\n",
    "print(\"Column names of the Ames dataset:\")\n",
    "print(ames_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of the Ames dataset:\n",
      "['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig']\n",
      "['LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd']\n",
      "['RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual']\n",
      "['BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC']\n",
      "['CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath']\n",
      "['BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt', 'GarageFinish']\n",
      "['GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']\n",
      "['PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "# Print the column names of the Ames dataset in groups of 5\n",
    "columns = ames_df.columns.tolist()\n",
    "print(\"Column names of the Ames dataset:\")\n",
    "\n",
    "for i in range(0, len(columns), 10):\n",
    "    print(columns[i:i+10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Basic Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Histograms for key features\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_df\u001b[38;5;241m.\u001b[39mhist(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m), color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# create histograms for all numerical features in the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m                       \u001b[38;5;66;03m# display the plots\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backend_bases.py:2342\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2336\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m _get_renderer(\n\u001b[1;32m   2337\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure,\n\u001b[1;32m   2338\u001b[0m         functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m   2339\u001b[0m             print_method, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[1;32m   2340\u001b[0m     )\n\u001b[1;32m   2341\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2342\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/figure.py:3175\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3175\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[1;32m   3179\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py:3028\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3025\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m spine \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspines\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m   3026\u001b[0m         artists\u001b[38;5;241m.\u001b[39mremove(spine)\n\u001b[0;32m-> 3028\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_title_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxison:\n\u001b[1;32m   3031\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _axis \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_axis_map\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axes/_base.py:2972\u001b[0m, in \u001b[0;36m_AxesBase._update_title_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2970\u001b[0m top \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(top, bb\u001b[38;5;241m.\u001b[39mymax)\n\u001b[1;32m   2971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m title\u001b[38;5;241m.\u001b[39mget_text():\n\u001b[0;32m-> 2972\u001b[0m     \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# update offsetText\u001b[39;00m\n\u001b[1;32m   2973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39moffsetText\u001b[38;5;241m.\u001b[39mget_text():\n\u001b[1;32m   2974\u001b[0m         bb \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39moffsetText\u001b[38;5;241m.\u001b[39mget_tightbbox(renderer)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axis.py:1335\u001b[0m, in \u001b[0;36mAxis.get_tightbbox\u001b[0;34m(self, renderer, for_layout_only)\u001b[0m\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1334\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[0;32m-> 1335\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_label_position(renderer)\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;66;03m# go back to just this axis's tick labels\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axis.py:1276\u001b[0m, in \u001b[0;36mAxis._update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1274\u001b[0m major_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_majorticklocs()\n\u001b[1;32m   1275\u001b[0m major_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mformat_ticks(major_locs)\n\u001b[0;32m-> 1276\u001b[0m major_ticks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_major_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmajor_locs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;241m.\u001b[39mformatter\u001b[38;5;241m.\u001b[39mset_locs(major_locs)\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick, loc, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(major_ticks, major_locs, major_labels):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axis.py:1629\u001b[0m, in \u001b[0;36mAxis.get_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1627\u001b[0m     tick \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tick(major\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajorTicks\u001b[38;5;241m.\u001b[39mappend(tick)\n\u001b[0;32m-> 1629\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy_tick_props\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmajorTicks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtick\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajorTicks[:numticks]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/axis.py:1583\u001b[0m, in \u001b[0;36mAxis._copy_tick_props\u001b[0;34m(self, src, dest)\u001b[0m\n\u001b[1;32m   1581\u001b[0m dest\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mupdate_from(src\u001b[38;5;241m.\u001b[39mlabel1)\n\u001b[1;32m   1582\u001b[0m dest\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mupdate_from(src\u001b[38;5;241m.\u001b[39mlabel2)\n\u001b[0;32m-> 1583\u001b[0m \u001b[43mdest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick1line\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick1line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1584\u001b[0m dest\u001b[38;5;241m.\u001b[39mtick2line\u001b[38;5;241m.\u001b[39mupdate_from(src\u001b[38;5;241m.\u001b[39mtick2line)\n\u001b[1;32m   1585\u001b[0m dest\u001b[38;5;241m.\u001b[39mgridline\u001b[38;5;241m.\u001b[39mupdate_from(src\u001b[38;5;241m.\u001b[39mgridline)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/lines.py:1354\u001b[0m, in \u001b[0;36mLine2D.update_from\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solidjoinstyle \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_solidjoinstyle\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linestyle \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_linestyle\n\u001b[0;32m-> 1354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_marker \u001b[38;5;241m=\u001b[39m \u001b[43mMarkerStyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_marker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drawstyle \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39m_drawstyle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/markers.py:272\u001b[0m, in \u001b[0;36mMarkerStyle.__init__\u001b[0;34m(self, marker, fillstyle, transform, capstyle, joinstyle)\u001b[0m\n\u001b[1;32m    267\u001b[0m     marker \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m\"\u001b[39m, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarkerStyle(None) is deprecated since \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; support will be removed \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.  Use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMarkerStyle(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) to construct an empty MarkerStyle.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/markers.py:355\u001b[0m, in \u001b[0;36mMarkerStyle._set_marker\u001b[0;34m(self, marker)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_marker_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_set_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkers[marker])\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(marker, MarkerStyle):\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/path.py:281\u001b[0m, in \u001b[0;36mPath.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    Return a shallow copy of the `Path`, which will share the\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    vertices and codes with the source `Path`.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__deepcopy__\u001b[39m(\u001b[38;5;28mself\u001b[39m, memo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    282\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    Return a deepcopy of the `Path`.  The `Path` will not be\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03m    readonly, even if the source `Path` is.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# Deepcopying arrays (vertices, codes) strips the writeable=False flag.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Histograms for key features\n",
    "train_df.hist(figsize=(20, 20), color = 'blue')  # create histograms for all numerical features in the dataset\n",
    "plt.show()                       # display the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of overall quality\n",
    "plt.figure(figsize=(10, 6))  # set the figure size\n",
    "sns.countplot(x='OverallQual', data=train_df, color = 'blue')  # create a count plot for the OverallQual column\n",
    "plt.title('Overall Quality Distribution')  # add a title to the plot\n",
    "plt.show()  # display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of sale prices\n",
    "plt.figure(figsize=(10, 6))  # set the figure size\n",
    "sns.histplot(train_df['SalePrice'], bins=50, kde=True, color ='darkorange')  # create a histogram with a kernel density estimate for the SalePrice column\n",
    "plt.title('Distribution of Sale Prices')  # add a title to the plot\n",
    "plt.show()  # display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Scatter plot of square footage vs. house price\n",
    "plt.figure(figsize=(6, 4))  # Set the figure size\n",
    "sns.scatterplot(x='GrLivArea', y='SalePrice', data=train_df, color = 'blue')  # Create a scatter plot for square footage (GrLivArea) vs. house price (SalePrice)\n",
    "plt.title('Square Footage vs. SalePrice')  # Add a title to the plot\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Scatter plot of age of home vs. house price\n",
    "plt.figure(figsize=(6, 4))  # Set the figure size\n",
    "sns.scatterplot(x='YearBuilt', y='SalePrice', data=train_df, color = 'blue')  # Create a scatter plot for the age of home (YearBuilt) vs. house price (SalePrice)\n",
    "plt.title('Age of Home vs. SalePrice')  # Add a title to the plot\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Boxplot of neighborhood vs. house price\n",
    "plt.figure(figsize=(6, 4))  # Set the figure size\n",
    "sns.boxplot(x='Neighborhood', y='SalePrice', data=train_df, hue='Neighborhood', palette = 'Blues')  # Create a box plot for neighborhood (Neighborhood) vs. house price (SalePrice)\n",
    "plt.title('Neighborhood vs. SalePrice')  # Add a title to the plot\n",
    "plt.xticks(rotation=90)  # Rotate the x-axis labels by 90 degrees for better readability\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Boxplot of neighborhood vs. house price\n",
    "plt.figure(figsize=(6, 4))  # Set the figure size\n",
    "sns.boxplot(x='OverallQual', y='SalePrice', data=train_df, hue='OverallQual', palette = 'Blues')  # Create a box plot \n",
    "plt.title('Overall Quality vs SalePrice')  # Add a title to the plot\n",
    "plt.xticks(rotation=90)  # Rotate the x-axis labels by 90 degrees for better readability\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Boxplot of year built vs. sale price\n",
    "plt.figure(figsize=(18, 4))  # Set the figure size\n",
    "sns.boxplot(x='YearBuilt', y='SalePrice', data=train_df, hue='YearBuilt', palette = 'Blues')  # Create a box plot for year built (YearBuilt) vs. house price (SalePrice)\n",
    "plt.title('YearBuilt vs. SalePrice')  # Add a title to the plot\n",
    "plt.xticks(rotation=90)  # Rotate the x-axis labels by 90 degrees for better readability\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot\n",
    "sns.set_theme(style=\"ticks\")\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(train_df[cols], height = 2.5, hue = 'SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only categorical columns\n",
    "categorical_cols = train_df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "# Determine the number of rows and columns for the subplot grid\n",
    "n_cols = 6\n",
    "n_rows = len(categorical_cols) // n_cols + (len(categorical_cols) % n_cols > 0)\n",
    "\n",
    "# Plot count plots for categorical features\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 3))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(categorical_cols):\n",
    "    sns.countplot(x=train_df[feature], ax=axes[i], hue=train_df[feature], palette=\"coolwarm\", dodge=False, legend=False)\n",
    "    axes[i].set_title(f'Distribution of {feature}')\n",
    "    axes[i].tick_params(axis='x', rotation=90, labelsize=8)\n",
    "    axes[i].tick_params(axis='y', labelsize=8)\n",
    "\n",
    "# Remove any unused subplots\n",
    "for ax in axes[len(categorical_cols):]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar plots for categorical features against mean SalePrice\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 3))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(categorical_cols):\n",
    "    sns.barplot(x=train_df[feature], y=train_df['SalePrice'], ax=axes[i], errorbar=None, hue=train_df[feature], palette=\"viridis\", dodge=False, legend=False)\n",
    "    axes[i].set_title(f'{feature} vs Mean SalePrice')\n",
    "    axes[i].tick_params(axis='x', rotation=90, labelsize=8)\n",
    "    axes[i].tick_params(axis='y', labelsize=8)\n",
    "\n",
    "# Remove any unused subplots\n",
    "for ax in axes[len(categorical_cols):]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize 'SalePrice'\n",
    "saleprice_scaled = StandardScaler().fit_transform(ames_df['SalePrice'].values.reshape(-1, 1))\n",
    "\n",
    "# Remove outliers based on 'GrLivArea'\n",
    "ames_df = ames_df.drop(ames_df[ames_df['GrLivArea'] > 4000].index)\n",
    "\n",
    "# Prepare features and target variable\n",
    "X = ames_df[['GrLivArea', 'TotalBsmtSF']]\n",
    "y = ames_df['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Baseline Linear Regression Model Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='blue', label='Data Points')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Regression Line')\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs Predicted SalePrice')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the regression coefficients\n",
    "print(f\"Regression Coefficients: {lin_reg.coef_}\")\n",
    "print(f\"Intercept: {lin_reg.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numeric_cols.corr()\n",
    "\n",
    "# Select key features for correlation analysis\n",
    "key_features = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'YearBuilt']\n",
    "\n",
    "# Filter the correlation matrix for the key features\n",
    "key_correlation_matrix = correlation_matrix.loc[key_features, key_features]\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(key_correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Key Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = numeric_cols.corr()\n",
    "\n",
    "# Display the first few rows of the correlation matrix to verify it's calculated correctly\n",
    "print(\"Correlation Matrix:\")\n",
    "correlation_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the correlation matrix above, as a heatmap\n",
    "# Function to adjust tick labels\n",
    "def adjust_tick_labels(ax):\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "    for tick in ax.get_yticklabels():\n",
    "        tick.set_rotation(0)\n",
    "\n",
    "# Example usage in a heatmap with the selected correlation matrix\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Plot the heatmap with adjusted annotation font size\n",
    "sns.heatmap(correlation_matrix, annot=True, annot_kws={\"size\": 8}, cmap='viridis', fmt=\".2f\",\n",
    "            cbar_kws={'shrink': 0.5})  # Shrink the color bar\n",
    "\n",
    "# Adjust tick labels\n",
    "ax = plt.gca()\n",
    "adjust_tick_labels(ax)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "\n",
    "plt.title('Correlation Matrix of All Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the Correlation Matrix is symmetrical, removing the top half above the diagonal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)   # k=1 to exclude the diagonal from masking\n",
    "\n",
    "# Plot the heatmap with the mask\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, annot_kws={\"size\": 8}, cmap='viridis', fmt=\".2f\",\n",
    "            cbar_kws={'shrink': 0.5})  # Shrink the color bar\n",
    "\n",
    "# Adjust tick labels\n",
    "ax = plt.gca()\n",
    "adjust_tick_labels(ax)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "\n",
    "plt.title('Correlation Matrix of All Numerical Features (Lower Triangle) with Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Data Processing and Feature Engineering\n",
    "#### Feature Selection Using Random Forest\n",
    "**1. One-Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to integer\n",
    "bool_cols = train_df.select_dtypes(include=[bool]).columns.tolist()\n",
    "train_df[bool_cols] = train_df[bool_cols].astype(int)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "train_df = pd.get_dummies(train_df, drop_first=True)\n",
    "\n",
    "# Update numerical columns after one-hot encoding\n",
    "numerical_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Model Training and Evaluation - Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable and features\n",
    "X = train_df.drop('SalePrice', axis=1)\n",
    "y = train_df['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(\"Random Forest Regressor Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "all_features = X.columns\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances_df.head(40))\n",
    "plt.title('Top 40 Feature Importances in Random Forest Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the preprocessing pipeline applies transformations like one-hot encoding, it generates new feature names based on the original categorical variables.\n",
    "(i.e. Foundation -> Foundation_CBlock, or RoofStyle -> RoofStyle_Hip)\n",
    "These new names include the original variable names with appended values, creating a more detailed representation.\n",
    "\n",
    "To address this and create pair plots effectively, we need to:\n",
    "\n",
    "- Identify the original feature names from the transformed dataset.\n",
    "- Map the new feature names back to the original feature names.\n",
    "- Use the top 30 features (or their respective original names) for the pair plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of top features to select\n",
    "num_features = 30  # change this number as needed to select the top X features\n",
    "\n",
    "# Hyperparameter Tuning Using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define a more efficient parameter grid for quicker optimization\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Define the RandomizedSearchCV with fewer iterations\n",
    "rf_random = RandomizedSearchCV( estimator=RandomForestRegressor(),\n",
    "                                param_distributions=param_grid,\n",
    "                                n_iter=10, cv=3, verbose=2,\n",
    "                                random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = rf_random.best_params_\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "rf_optimized = RandomForestRegressor(**best_params)\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_optimized = rf_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_optimized = mean_absolute_error(y_test, y_pred_optimized)\n",
    "mse_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "\n",
    "# Display the results\n",
    "print(\"Optimized Random Forest Regressor Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_optimized}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_optimized}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importances = rf_optimized.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the top X features\n",
    "top_X_features = feature_importances_df.head(num_features)['Feature'].tolist()\n",
    "print(f\"Top {num_features} Features:\")\n",
    "# print(top_X_features)\n",
    "top_X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances_df.head(num_features))\n",
    "plt.title(f'Top {num_features} Feature Importances in Optimized Random Forest Regressor')\n",
    "plt.show()\n",
    "\n",
    "# Map the new feature names back to the original feature names\n",
    "original_features = []\n",
    "for feature in top_X_features:\n",
    "    if '_' in feature:\n",
    "        original_features.append(feature.split('_')[0])\n",
    "    else:\n",
    "        original_features.append(feature)\n",
    "\n",
    "# Remove duplicates while preserving order\n",
    "original_features = list(dict.fromkeys(original_features))\n",
    "\n",
    "# Check if the original features exist in the dataframe and filter\n",
    "filtered_features = [feature for feature in original_features if feature in train_df.columns]\n",
    "\n",
    "# Add SalePrice to the list of top original features\n",
    "filtered_features.append('SalePrice')\n",
    "\n",
    "print(\"Filtered Top Original Features for Pair Plot:\")\n",
    "print(filtered_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for the filtered top original features\n",
    "#sns.set_theme(style=\"ticks\")\n",
    "#sns.pairplot(train_df[filtered_features], height=2.5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 40 features for further analysis\n",
    "top_40_features = feature_importances_df.head(40)['Feature'].tolist()\n",
    "# Violin plot for the top 10 features\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.violinplot(data=train_df[top_40_features], inner=\"quartile\")\n",
    "plt.title('Violin Plot for Top 40 Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Divide top 40 features into groups of 10 for violin plots\n",
    "top_20_features = top_40_features[:20]\n",
    "next_20_features = top_40_features[20:40]\n",
    "\n",
    "# Violin plot for the top 10 features\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.violinplot(data=train_df[top_20_features], inner=\"quartile\")\n",
    "plt.title('Violin Plot for Top 20 Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Violin plot for the next 10 features\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.violinplot(data=train_df[next_20_features], inner=\"quartile\")\n",
    "plt.title('Violin Plot for Next 20 Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Histogram for combinations of the top 40 features\n",
    "for i in range(len(top_40_features) - 1):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    feature1 = train_df[top_40_features[i]]\n",
    "    feature2 = train_df[top_40_features[i + 1]]\n",
    "\n",
    "    # Check if both features are numeric\n",
    "    if pd.api.types.is_numeric_dtype(feature1) and pd.api.types.is_numeric_dtype(feature2):\n",
    "        # Drop any rows with missing values for the selected features and synchronize their indices\n",
    "        combined = pd.concat([feature1, feature2], axis=1).dropna()\n",
    "        feature1_clean = combined.iloc[:, 0]\n",
    "        feature2_clean = combined.iloc[:, 1]\n",
    "        \n",
    "        plt.hist2d(feature1_clean, feature2_clean, bins=40, cmap='viridis')\n",
    "        plt.colorbar()\n",
    "        plt.title(f'2D Histogram of {top_40_features[i]} and {top_40_features[i + 1]}')\n",
    "        plt.xlabel(top_40_features[i])\n",
    "        plt.ylabel(top_40_features[i + 1])\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Skipping features {top_40_features[i]} and {top_40_features[i + 1]} as they are not numeric.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotated heatmap for top 40 features\n",
    "plt.figure(figsize=(16, 12))\n",
    "correlation_matrix_top_40 = train_df[top_40_features].corr()\n",
    "sns.heatmap(correlation_matrix_top_40, annot=False, cmap='coolwarm')\n",
    "plt.title('Heatmap for Top 40 Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Curve with error bands for one of the top features\n",
    "feature = top_40_features[4]\n",
    "X = sm.add_constant(train_df[feature])\n",
    "model = sm.OLS(train_df['SalePrice'], X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_df[feature], train_df['SalePrice'], 'o', label='data', color='turquoise')\n",
    "plt.plot(train_df[feature], predictions, 'r--.', label='OLS fit')\n",
    "# Use iloc for positional indexing to avoid the warning\n",
    "plt.fill_between(train_df[feature], predictions - 1.96 * model.bse.iloc[1], predictions + 1.96 * model.bse.iloc[1], color='red', alpha=0.2)\n",
    "plt.xlabel(feature)\n",
    "plt.ylabel('SalePrice')\n",
    "plt.title(f'OLS Fit with Error Bands for {feature}')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = train_df.isnull().sum()\n",
    "missing_columns = missing_values[missing_values > 0]\n",
    "\n",
    "if not missing_columns.empty:\n",
    "    print(\"Columns with missing values and their counts:\")\n",
    "    print(missing_columns)\n",
    "else:\n",
    "    print(\"No missing values in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further Optimizing Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "## Commenting these out because this block is run in the previous cells - but if ran separately, uncomment this block\n",
    "## Convert boolean columns to integer\n",
    "# bool_cols = train_df.select_dtypes(include=[bool]).columns.tolist()\n",
    "# train_df[bool_cols] = train_df[bool_cols].astype(int)\n",
    "\n",
    "## Handle missing values\n",
    "# imputer = SimpleImputer(strategy='median')\n",
    "# train_df[train_df.columns] = imputer.fit_transform(train_df)\n",
    "\n",
    "## One-hot encode categorical variables\n",
    "# train_df = pd.get_dummies(train_df, drop_first=True)\n",
    "\n",
    "## Update numerical columns after one-hot encoding\n",
    "# numerical_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "## Standardize numerical features\n",
    "# scaler = StandardScaler()\n",
    "# train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n",
    "\n",
    "## Separate the target variable and features\n",
    "# X = train_df.drop('SalePrice', axis=1)\n",
    "# y = train_df['SalePrice']\n",
    "\n",
    "\n",
    "# Add Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the number of top features to select\n",
    "num_features = 30  # change this number as needed to select the top X features\n",
    "\n",
    "# Hyperparameter Tuning Using RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [None, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Define the RandomizedSearchCV with cross-validation\n",
    "rf_random = RandomizedSearchCV(estimator=RandomForestRegressor(),\n",
    "                               param_distributions=param_grid,\n",
    "                               n_iter=100, cv=5, verbose=2,\n",
    "                               random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = rf_random.best_params_\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "rf_optimized = RandomForestRegressor(**best_params)\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation for better performance estimation\n",
    "cv_scores = cross_val_score(rf_optimized, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(f\"Cross-validated MAE: {-np.mean(cv_scores)}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_optimized = rf_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_optimized = mean_absolute_error(y_test, y_pred_optimized)\n",
    "mse_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "\n",
    "# Display the results\n",
    "print(\"Optimized Random Forest Regressor Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_optimized}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_optimized}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importances = rf_optimized.feature_importances_\n",
    "\n",
    "# Since we used polynomial features, we need to get the feature names from PolynomialFeatures\n",
    "feature_names = poly.get_feature_names_out(input_features=X.columns)\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Get the original feature names\n",
    "original_feature_names = feature_importances_df.head(num_features)['Feature'].tolist()\n",
    "\n",
    "# Print the top X features with their original names\n",
    "print(f\"Top {num_features} Features with Original Names:\")\n",
    "print(original_feature_names)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances_df.head(40))\n",
    "plt.title('Top 40 Feature Importances in Random Forest Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Polynomial Features with Random Forest Regressor\n",
    "\n",
    " -  In an attempt to improve the performance of our Random Forest Regressor for predicting house prices, we incorporated polynomial features into the dataset. Polynomial features can capture      interaction effects between variables, potentially improving the model's predictive power. However, this comes at the cost of increased computational complexity.\n",
    "\n",
    "**Experiment**\n",
    "\n",
    "**1. Data Preprocessing:**\n",
    "-   Converted boolean columns to integers.\n",
    "-   Handled missing values using the median strategy.\n",
    "-   One-hot encoded categorical variables.\n",
    "-   Standardized numerical features.\n",
    "\n",
    "**2. Polynomial Features:**\n",
    "\n",
    "    Added polynomial features (degree=2, interaction-only) to the dataset to capture interactions between variables.\n",
    "\n",
    "**3. Model Training:**\n",
    "-   Used RandomizedSearchCV to optimize the hyperparameters of the Random Forest Regressor.\n",
    "-   Evaluated the model using cross-validation to ensure robust performance metrics.\n",
    "\n",
    "**Results**\n",
    "\n",
    "    Despite adding polynomial features, the performance of the Random Forest Regressor did not improve significantly.\n",
    "\n",
    "    The optimized model achieved the following metrics:\n",
    "        Cross-validated MAE: 0.2046\n",
    "        Optimized MAE: 0.1769\n",
    "        Optimized MSE: 0.0629\n",
    "        Runtime: 13m43s\n",
    "        Best Parameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "    The addition of polynomial features did not lead to a noticeable improvement in the performance of the Random Forest Regressor. This suggests that the model might not benefit significantly from the interaction terms or that the current feature engineering approach needs further refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next Steps**\n",
    "\n",
    "- While polynomial features did not enhance the Random Forest model's performance, there are several avenues for further improvement:\n",
    "\n",
    "**Refine Feature Engineering:**\n",
    "\n",
    "- Explore different polynomial degrees or additional feature transformations.\n",
    "\n",
    "**Alternative Models:**\n",
    "\n",
    "- Investigate other models such as Gradient Boosting, XGBoost, or LightGBM, which may better capture the complexities of the dataset.\n",
    "\n",
    "**Model Stacking:**\n",
    "\n",
    "- Combine multiple models to leverage their strengths and potentially improve overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "Ridge Regression is used to address multicollinearity and overfitting by applying a penalty value to large coefficents. We can now apply a Ridge Regression to the Ames data set since it has been preprocessed, split into a test and train and standardized to fit our various models consistently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the Ames dataset\n",
    "ames_df = pd.read_csv(\"/workspaces/DataScience/data/AmesData.csv\")\n",
    "\n",
    "# Handle missing values by filling them with the median value for numerical columns and the mode for categorical columns\n",
    "for column in ames_df.select_dtypes(include=['number']).columns:\n",
    "    ames_df[column].fillna(ames_df[column].median(), inplace=True)\n",
    "for column in ames_df.select_dtypes(include=['object']).columns:\n",
    "    ames_df[column].fillna(ames_df[column].mode()[0], inplace=True)\n",
    "\n",
    "# Convert categorical variables to dummy/indicator variables\n",
    "ames_df = pd.get_dummies(ames_df)\n",
    "\n",
    "# Log transform skewed numerical features to reduce the impact of outliers\n",
    "numeric_features = ames_df.select_dtypes(include=[np.number])\n",
    "skewed_features = numeric_features.apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "high_skew = skewed_features[abs(skewed_features) > 0.5]\n",
    "skewed_features_index = high_skew.index\n",
    "\n",
    "for feature in skewed_features_index:\n",
    "    ames_df[feature] = np.log1p(ames_df[feature])\n",
    "\n",
    "# Separate the target variable (SalePrice) and features\n",
    "X = ames_df.drop(columns=['SalePrice'])\n",
    "y = ames_df['SalePrice']\n",
    "\n",
    "# Split into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_scaled = scaler.transform(X_test_poly)\n",
    "\n",
    "# Define the parameter grid for alpha with a finer range\n",
    "param_grid = {'alpha': [0.01, 0.1, 1, 10, 50, 100, 500, 1000, 5000, 10000]}\n",
    "\n",
    "# Initialize and train the Ridge Regression model with GridSearchCV\n",
    "ridge_model = Ridge()\n",
    "grid_search = GridSearchCV(estimator=ridge_model, param_grid=param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and the best score\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Train the Ridge Regression model with the best alpha\n",
    "best_ridge_model = Ridge(alpha=best_alpha)\n",
    "best_ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_train_pred = best_ridge_model.predict(X_train_scaled)\n",
    "y_test_pred = best_ridge_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model with the best alpha\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"Best cross-validation R-squared: {best_score}\")\n",
    "print(\"Ridge Regression Results with Best Alpha:\")\n",
    "print(f\"Training Mean Squared Error (MSE): {train_mse}\")\n",
    "print(f\"Testing Mean Squared Error (MSE): {test_mse}\")\n",
    "print(f\"Training R-squared (R²): {train_r2}\")\n",
    "print(f\"Testing R-squared (R²): {test_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **XGBoost Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Define the RandomizedSearchCV with cross-validation\n",
    "xgb_random = RandomizedSearchCV(estimator=XGBRegressor(),\n",
    "                                param_distributions=param_grid,\n",
    "                                n_iter=100, cv=5, verbose=2,\n",
    "                                random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the RandomizedSearchCV\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = xgb_random.best_params_\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "xgb_optimized = XGBRegressor(**best_params)\n",
    "xgb_optimized.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation for better performance estimation\n",
    "cv_scores = cross_val_score(xgb_optimized, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(f\"Cross-validated MAE: {-np.mean(cv_scores)}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_optimized = xgb_optimized.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_optimized = mean_absolute_error(y_test, y_pred_optimized)\n",
    "mse_optimized = mean_squared_error(y_test, y_pred_optimized)\n",
    "\n",
    "# Display the results\n",
    "print(\"Optimized XGBoost Regressor Performance:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_optimized}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_optimized}\")\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Evaluate feature importance\n",
    "feature_importances = xgb_optimized.feature_importances_\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the top X features with their original names\n",
    "top_X_features = feature_importances_df.head(num_features)['Feature'].tolist()\n",
    "print(f\"Top {num_features} Features with Original Names:\")\n",
    "print(top_X_features)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances_df.head(40))\n",
    "plt.title('Top 40 Feature Importances in XGBoost Regressor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-calculate the performance metrics on the original scale\n",
    "# Transform back the log predictions and the actual values\n",
    "y_test_original = np.exp(y_test)\n",
    "y_pred_original = np.exp(y_pred)\n",
    "\n",
    "# Evaluate the model on the original scale\n",
    "mae_original = mean_absolute_error(y_test_original, y_pred_original)\n",
    "mse_original = mean_squared_error(y_test_original, y_pred_original)\n",
    "\n",
    "# Print results\n",
    "print(f\"Baseline Simple Linear Regression Model (Original Scale):\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_original}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_original}\")\n",
    "\n",
    "# Plot actual vs predicted on the original scale\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(y_test_original, y_pred_original, color='turquoise')  # Replace custom_palette with a color\n",
    "plt.plot([min(y_test_original), max(y_test_original)], [min(y_test_original), max(y_test_original)], 'r', linewidth=2)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs Predicted SalePrice (Original Scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ames_df[filtered_features]\n",
    "y = ames_df['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the SVR model\n",
    "svr_model = SVR()\n",
    "\n",
    "# Define parameter grid\n",
    "svr_params = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "svr_search = GridSearchCV(svr_model, svr_params, cv=5)\n",
    "svr_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_svr_params = svr_search.best_params_\n",
    "\n",
    "# Make predictions\n",
    "svr_pred = svr_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "svr_mae = mean_absolute_error(y_test, svr_pred)\n",
    "svr_mse = mean_squared_error(y_test, svr_pred)\n",
    "\n",
    "print(f\"SVR Performance:\\nBest Parameters: {best_svr_params}\\nMean Absolute Error (MAE): {svr_mae}\\nMean Squared Error (MSE): {svr_mse}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, svr_pred, color='blue', label='SVR Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2, label='Ideal Fit')\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs Predicted SalePrice (SVR)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Define parameter grid\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "xgb_search = RandomizedSearchCV(xgb_model, xgb_params, n_iter=10, cv=5, random_state=42, n_jobs=-1)\n",
    "xgb_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_xgb_params = xgb_search.best_params_\n",
    "\n",
    "# Make predictions\n",
    "xgb_pred = xgb_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "xgb_mse = mean_squared_error(y_test, xgb_pred)\n",
    "\n",
    "print(f\"XGBoost Performance:\\nBest Parameters: {best_xgb_params}\\nMean Absolute Error (MAE): {xgb_mae}\\nMean Squared Error (MSE): {xgb_mse}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, xgb_pred, color='blue', label='XGBoost Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2, label='Ideal Fit')\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs Predicted SalePrice (XGBoost)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "# Use the best hyperparameters found previously\n",
    "best_ridge_params = {'alpha': 100}  # Update with the actual best parameter for optimization \n",
    "best_lasso_params = {'alpha': 0.001}  # Update with the actual best parameter for optimization \n",
    "best_elasticnet_params = {'alpha': 0.01, 'l1_ratio': 0.1}  # Update with the actual best parameters\n",
    "\n",
    "# Define individual models with the best hyperparameters\n",
    "ridge_model = Ridge(alpha=best_ridge_params['alpha'])\n",
    "lasso_model = Lasso(alpha=best_lasso_params['alpha'])\n",
    "elasticnet_model = ElasticNet(alpha=best_elasticnet_params['alpha'], l1_ratio=best_elasticnet_params['l1_ratio'])\n",
    "\n",
    "# Define the ensemble model\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('ridge', ridge_model),\n",
    "    ('lasso', lasso_model),\n",
    "    ('elasticnet', elasticnet_model),\n",
    "    ('svr', svr_search.best_estimator_),\n",
    "    ('xgb', xgb_search.best_estimator_)\n",
    "])\n",
    "\n",
    "# Train the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "ensemble_mae = mean_absolute_error(y_test, ensemble_pred)\n",
    "ensemble_mse = mean_squared_error(y_test, ensemble_pred)\n",
    "\n",
    "print(f\"Ensemble Model Performance:\\nMean Absolute Error (MAE): {ensemble_mae}\\nMean Squared Error (MSE): {ensemble_mse}\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, ensemble_pred, color='blue', label='Ensemble Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2, label='Ideal Fit')\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs Predicted SalePrice (Ensemble Model)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artificial Neural Network (ANN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
