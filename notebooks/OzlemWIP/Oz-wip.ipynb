{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is my Work In Progress File. \n",
    "\n",
    "The code blocks in this file initially ran, but after making some changes to the code (for example implementing the one-hot encoding, or selecting the most important features first, and changing the dataset etc.), the snippets gave me error. I will store my wip here to explore later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a function to evaluate the model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Transform back to the original scale\n",
    "    y_test_original = np.exp(y_test)\n",
    "    y_pred_original = np.exp(y_pred)\n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "    mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "    return mae, mse, y_test_original, y_pred_original\n",
    "\n",
    "# Define the models and their parameter grids\n",
    "models = {\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Ridge': {'alpha': [0.1, 1.0, 10.0, 100.0]},\n",
    "    'Lasso': {'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0]},\n",
    "    'ElasticNet': {'alpha': [0.1, 1.0, 10.0, 100.0], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "}\n",
    "\n",
    "# Perform Grid Search with Cross-Validation\n",
    "best_models = {}\n",
    "for model_name in models:\n",
    "    print(f\"Training {model_name}...\")\n",
    "    grid_search = GridSearchCV(models[model_name], params[model_name], cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "\n",
    "# Evaluate the best models\n",
    "results = {}\n",
    "for model_name in best_models:\n",
    "    mae, mse, y_test_original, y_pred_original = evaluate_model(best_models[model_name], X_train, X_test, y_train, y_test)\n",
    "    results[model_name] = {'MAE': mae, 'MSE': mse}\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test_original, y_pred_original, color=custom_palette[8])\n",
    "    plt.plot([min(y_test_original), max(y_test_original)], [min(y_test_original), max(y_test_original)], 'r', linewidth=2)\n",
    "    plt.xlabel('Actual SalePrice')\n",
    "    plt.ylabel('Predicted SalePrice')\n",
    "    plt.title(f'Actual vs Predicted SalePrice ({model_name})')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Revised Approach**\n",
    "- **Include More Features: Add more relevant features to the model.**\n",
    "- **Extensive Hyperparameter Tuning: Use a more comprehensive grid for hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation for skewed numerical features\n",
    "ames_df['SalePrice'] = np.log(ames_df['SalePrice'])\n",
    "ames_df['GrLivArea'] = np.log(ames_df['GrLivArea'])\n",
    "ames_df['MasVnrArea'] = np.log1p(ames_df['MasVnrArea'])\n",
    "\n",
    "# Creating a binary variable 'HasBsmt'\n",
    "ames_df['HasBsmt'] = 0\n",
    "ames_df.loc[ames_df['TotalBsmtSF'] > 0, 'HasBsmt'] = 1\n",
    "\n",
    "# Applying log transformation to 'TotalBsmtSF' for non-zero values\n",
    "ames_df.loc[ames_df['HasBsmt'] == 1, 'TotalBsmtSF'] = np.log(ames_df.loc[ames_df['HasBsmt'] == 1, 'TotalBsmtSF'])\n",
    "\n",
    "# Convert categorical variables into dummy variables\n",
    "ames_df = pd.get_dummies(ames_df, drop_first=True)\n",
    "\n",
    "# Separate the target variable and features\n",
    "X = ames_df.drop('SalePrice', axis=1)\n",
    "y = ames_df['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train[X_train.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(X_train.select_dtypes(include=[np.number]))\n",
    "X_test[X_test.select_dtypes(include=[np.number]).columns] = scaler.transform(X_test.select_dtypes(include=[np.number]))\n",
    "\n",
    "# Define the hyperparameter grid for Ridge, Lasso, and ElasticNet\n",
    "param_grid = {\n",
    "    'ridge': {'alpha': [0.1, 1, 10, 100, 200]},\n",
    "    'lasso': {'alpha': [0.001, 0.01, 0.1, 1, 10]},\n",
    "    'elasticnet': {'alpha': [0.1, 1, 10, 100], 'l1_ratio': [0.2, 0.5, 0.7, 0.9]}\n",
    "}\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'elasticnet': ElasticNet()\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning and evaluation\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid[model_name], cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models[model_name] = grid_search.best_estimator_\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"{model_name.capitalize()} Performance:\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, color='orange')\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r', linewidth=2)\n",
    "    plt.xlabel('Actual SalePrice')\n",
    "    plt.ylabel('Predicted SalePrice')\n",
    "    plt.title(f'Actual vs Predicted SalePrice ({model_name.capitalize()})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Mean Absolute Error (MAE):** The MAE represents the average absolute difference between the predicted values and the actual values. A lower MAE indicates better model performance. An MAE of 0.0737 suggests that, on average, the model's predictions are very close to the actual values.\n",
    "\n",
    "- **Mean Squared Error (MSE):** The MSE is the average of the squared differences between predicted values and actual values.\n",
    "\n",
    "- Like MAE, a lower MSE indicates better performance. An MSE of 0.0102 indicates that the model's predictions have a small error variance.\n",
    "\n",
    "#### Comparison to Previous Results:\n",
    "\n",
    "These metrics are notably better compared to the initial baseline model and other regression models we've tried. \n",
    "\n",
    "The MAE is significantly lower, indicating more accurate predictions.\n",
    "The MSE is also much lower, suggesting less variability in the prediction errors.\n",
    "\n",
    "- **Visualization**\n",
    "\n",
    "The scatter plot of actual vs. predicted SalePrice for the ElasticNet model visually show the improvements, indicating how closely the predictions align with the actual values. A tighter cluster around the diagonal line (where predicted equals actual) confirm the model's accuracy.\n",
    "\n",
    "#### ElasticNet:\n",
    "\n",
    "The ElasticNet model has the highest MAE and MSE among the three models. This indicates it has the least accuracy and higher error variance.\n",
    "Lasso:\n",
    "\n",
    "The Lasso model performs better than ElasticNet with a lower MAE and MSE. This suggests it provides more accurate predictions with less variability in errors.\n",
    "Ridge:\n",
    "\n",
    "The Ridge model outperforms both ElasticNet and Lasso in terms of MAE and MSE. It has the lowest MAE and MSE, indicating the highest accuracy and least error variance among the three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cross-Validation\n",
    "We'll perform k-fold cross-validation to ensure that the performance metrics are consistent across different subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the models\n",
    "ridge_model = Ridge(alpha=10)\n",
    "lasso_model = Lasso(alpha=0.001)\n",
    "elasticnet_model = ElasticNet(alpha=0.1, l1_ratio=0.2)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "ridge_cv_scores = cross_val_score(ridge_model, X, y, cv=10, scoring='neg_mean_absolute_error')\n",
    "lasso_cv_scores = cross_val_score(lasso_model, X, y, cv=10, scoring='neg_mean_absolute_error')\n",
    "elasticnet_cv_scores = cross_val_score(elasticnet_model, X, y, cv=10, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f\"Ridge CV Mean Absolute Error: {-ridge_cv_scores.mean()} (+/- {ridge_cv_scores.std() * 2})\")\n",
    "print(f\"Lasso CV Mean Absolute Error: {-lasso_cv_scores.mean()} (+/- {lasso_cv_scores.std() * 2})\")\n",
    "print(f\"ElasticNet CV Mean Absolute Error: {-elasticnet_cv_scores.mean()} (+/- {elasticnet_cv_scores.std() * 2})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Feature Analysis\n",
    "\n",
    "We'll analyze feature importance to understand which features contribute most to the modelâ€™s predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Ridge model on the full dataset\n",
    "ridge_model.fit(X, y)\n",
    "\n",
    "# Get feature importance (coefficients)\n",
    "ridge_feature_importances = pd.Series(ridge_model.coef_, index=X.columns)\n",
    "\n",
    "# Sort feature importances\n",
    "ridge_feature_importances = ridge_feature_importances.sort_values(ascending=False)\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "ridge_feature_importances.head(20).plot(kind='bar')\n",
    "plt.title('Feature Importances (Ridge Regression)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features to use\n",
    "selected_features = ['OverallQual', 'GrLivArea', '1stFlrSF', 'TotalBsmtSF', 'GarageCars', 'GarageArea',\n",
    "                     'YearBuilt', 'ExterQual_TA', 'BsmtFinSF1', 'GarageYrBlt', 'FullBath', 'YearRemodAdd',\n",
    "                     'LotArea', 'MasVnrArea', 'KitchenQual_TA', 'Fireplaces', 'TotRmsAbvGrd', '2ndFlrSF',\n",
    "                     'GarageFinish_Unf', 'BsmtQual_TA', 'OpenPorchSF', 'Foundation_PConc', 'Neighborhood_NridgHt',\n",
    "                     'LotFrontage', 'BsmtQual_Gd', 'ExterQual_Gd', 'WoodDeckSF', 'KitchenQual_Gd', 'BsmtUnfSF',\n",
    "                     'GarageType_Detchd', 'HalfBath', 'BsmtExposure_Gd', 'RoofStyle_Gable', 'BedroomAbvGr',\n",
    "                     'MSSubClass', 'RoofStyle_Hip', 'BsmtFullBath', 'Foundation_CBlock', 'BsmtFinType1_GLQ', \n",
    "                     'OverallCond']\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = ames_df[selected_features]\n",
    "y = ames_df['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_params = {'alpha': [0.1, 1.0, 10, 100]}\n",
    "ridge_model = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "best_ridge_params = ridge_model.best_params_\n",
    "\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "\n",
    "print(f\"Ridge Performance:\\nBest Parameters: {best_ridge_params}\\nMean Absolute Error (MAE): {ridge_mae}\\nMean Squared Error (MSE): {ridge_mse}\")\n",
    "\n",
    "\n",
    "\n",
    "# ElasticNet Regression\n",
    "elasticnet_params = {'alpha': [0.01, 0.1, 1.0], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "elasticnet_model = GridSearchCV(ElasticNet(), elasticnet_params, cv=5)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "best_elasticnet_params = elasticnet_model.best_params_\n",
    "\n",
    "elasticnet_pred = elasticnet_model.predict(X_test)\n",
    "# Run Lasso Regression\n",
    "lasso_model.fit(X_train, y_train)\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Plot actual vs predicted for each model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(y_test, ridge_pred, color='blue', label='Ridge Predictions')\n",
    "plt.scatter(y_test, lasso_pred, color='green', label='Lasso Predictions')\n",
    "plt.scatter(y_test, elasticnet_pred, color='orange', label='ElasticNet Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r', linewidth=2)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs Predicted SalePrice')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define the models\n",
    "ridge = Ridge(max_iter=10000)\n",
    "lasso = Lasso(max_iter=10000)\n",
    "elasticnet = ElasticNet(max_iter=10000)\n",
    "\n",
    "# Create pipelines for each model\n",
    "ridge_pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('model', ridge)\n",
    "])\n",
    "\n",
    "lasso_pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('model', lasso)\n",
    "])\n",
    "\n",
    "elasticnet_pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('model', elasticnet)\n",
    "])\n",
    "\n",
    "# Define parameter grids\n",
    "ridge_params = {'model__alpha': [0.01, 0.1, 1.0, 10, 100]}\n",
    "lasso_params = {'model__alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "elasticnet_params = {'model__alpha': [0.01, 0.1, 1.0], 'model__l1_ratio': [0.1, 0.5, 0.9]}\n",
    "\n",
    "# Grid search for each model\n",
    "ridge_search = GridSearchCV(ridge_pipeline, ridge_params, cv=5)\n",
    "lasso_search = GridSearchCV(lasso_pipeline, lasso_params, cv=5)\n",
    "elasticnet_search = GridSearchCV(elasticnet_pipeline, elasticnet_params, cv=5)\n",
    "\n",
    "# Fit and evaluate Ridge\n",
    "ridge_search.fit(X_train, y_train)\n",
    "best_ridge_params = ridge_search.best_params_\n",
    "ridge_pred = ridge_search.predict(X_test)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "\n",
    "print(f\"Ridge Performance:\\nBest Parameters: {best_ridge_params}\\nMean Absolute Error (MAE): {ridge_mae}\\nMean Squared Error (MSE): {ridge_mse}\")\n",
    "\n",
    "# Fit and evaluate Lasso\n",
    "lasso_search.fit(X_train, y_train)\n",
    "best_lasso_params = lasso_search.best_params_\n",
    "lasso_pred = lasso_search.predict(X_test)\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "\n",
    "print(f\"Lasso Performance:\\nBest Parameters: {best_lasso_params}\\nMean Absolute Error (MAE): {lasso_mae}\\nMean Squared Error (MSE): {lasso_mse}\")\n",
    "\n",
    "# Fit and evaluate ElasticNet\n",
    "elasticnet_search.fit(X_train, y_train)\n",
    "best_elasticnet_params = elasticnet_search.best_params_\n",
    "elasticnet_pred = elasticnet_search.predict(X_test)\n",
    "elasticnet_mae = mean_absolute_error(y_test, elasticnet_pred)\n",
    "elasticnet_mse = mean_squared_error(y_test, elasticnet_pred)\n",
    "\n",
    "print(f\"ElasticNet Performance:\\nBest Parameters: {best_elasticnet_params}\\nMean Absolute Error (MAE): {elasticnet_mae}\\nMean Squared Error (MSE): {elasticnet_mse}\")\n",
    "\n",
    "# Plot actual vs predicted for each model\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(y_test, ridge_pred, color='blue', label='Ridge Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r', linewidth=2)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Ridge Regression')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(y_test, lasso_pred, color='green', label='Lasso Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r', linewidth=2)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Lasso Regression')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(y_test, elasticnet_pred, color='orange', label='ElasticNet Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r', linewidth=2)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('ElasticNet Regression')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define the model\n",
    "xgboost_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Define parameter grid\n",
    "xgboost_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "xgboost_search = GridSearchCV(xgboost_model, xgboost_params, cv=5)\n",
    "xgboost_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_xgboost_params = xgboost_search.best_params_\n",
    "\n",
    "# Make predictions\n",
    "xgboost_pred = xgboost_search.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "xgboost_mae = mean_absolute_error(y_test, xgboost_pred)\n",
    "xgboost_mse = mean_squared_error(y_test, xgboost_pred)\n",
    "\n",
    "print(f\"XGBoost Performance:\\nBest Parameters: {best_xgboost_params}\\nMean Absolute Error (MAE): {xgboost_mae}\\nMean Squared Error (MSE): {xgboost_mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble (Voting Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Define the ensemble model\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('ridge', ridge_search.best_estimator_),\n",
    "    ('lasso', lasso_search.best_estimator_),\n",
    "    ('elasticnet', elasticnet_search.best_estimator_),\n",
    "    ('xgboost', xgboost_search.best_estimator_)\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ensemble_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "ensemble_mae = mean_absolute_error(y_test, ensemble_pred)\n",
    "ensemble_mse = mean_squared_error(y_test, ensemble_pred)\n",
    "\n",
    "print(f\"Ensemble Performance:\\nMean Absolute Error (MAE): {ensemble_mae}\\nMean Squared Error (MSE): {ensemble_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '../data/AmesData.csv'\n",
    "ames_df = pd.read_csv(file_path)\n",
    "\n",
    "# Replace blanks in 'MasVnrArea' with 0\n",
    "ames_df['MasVnrArea'].replace(np.nan, 0, inplace=True)\n",
    "\n",
    "# Apply log transformation to 'SalePrice'\n",
    "ames_df['SalePrice'] = np.log(ames_df['SalePrice'])\n",
    "\n",
    "# Create binary variable 'HasBsmt'\n",
    "ames_df['HasBsmt'] = 0\n",
    "ames_df.loc[ames_df['TotalBsmtSF'] > 0, 'HasBsmt'] = 1\n",
    "\n",
    "# Apply log transformation to 'TotalBsmtSF' for non-zero values\n",
    "ames_df.loc[ames_df['HasBsmt'] == 1, 'TotalBsmtSF'] = np.log(ames_df.loc[ames_df['HasBsmt'] == 1, 'TotalBsmtSF'])\n",
    "\n",
    "# Convert categorical variables into dummy variables\n",
    "ames_df = pd.get_dummies(ames_df, drop_first=True)\n",
    "\n",
    "# Select the top 40 features from Random Forest (Example)\n",
    "top_40_features = ['OverallQual', 'GrLivArea', '1stFlrSF', 'TotalBsmtSF', 'GarageCars', 'GarageArea',\n",
    "                   'YearBuilt', 'ExterQual_TA', 'BsmtFinSF1', 'GarageYrBlt', 'FullBath', 'YearRemodAdd',\n",
    "                   'LotArea', 'MasVnrArea', 'KitchenQual_TA', 'Fireplaces', 'TotRmsAbvGrd', '2ndFlrSF',\n",
    "                   'GarageFinish_Unf', 'BsmtQual_TA', 'OpenPorchSF', 'Foundation_PConc', 'Neighborhood_NridgHt',\n",
    "                   'LotFrontage', 'BsmtQual_Gd', 'ExterQual_Gd', 'WoodDeckSF', 'KitchenQual_Gd', 'BsmtUnfSF',\n",
    "                   'GarageType_Detchd', 'HalfBath', 'BsmtExposure_Gd', 'RoofStyle_Gable', 'BedroomAbvGr',\n",
    "                   'MSSubClass', 'RoofStyle_Hip', 'BsmtFullBath', 'Foundation_CBlock', 'BsmtFinType1_GLQ', \n",
    "                   'OverallCond']\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = ames_df[top_40_features]\n",
    "y = ames_df['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_params = {'model__alpha': [0.1, 1.0, 10, 100]}\n",
    "ridge_model = GridSearchCV(Ridge(), ridge_params, cv=5)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "best_ridge_params = ridge_model.best_params_\n",
    "\n",
    "ridge_pred = ridge_model.predict(X_test)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "print(f\"Ridge Performance:\\nBest Parameters: {best_ridge_params}\\nMean Absolute Error (MAE): {ridge_mae}\\nMean Squared Error (MSE): {ridge_mse}\")\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_params = {'model__alpha': [0.001, 0.01, 0.1, 1]}\n",
    "lasso_model = GridSearchCV(Lasso(), lasso_params, cv=5)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "best_lasso_params = lasso_model.best_params_\n",
    "\n",
    "lasso_pred = lasso_model.predict(X_test)\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "print(f\"Lasso Performance:\\nBest Parameters: {best_lasso_params}\\nMean Absolute Error (MAE): {lasso_mae}\\nMean Squared Error (MSE): {lasso_mse}\")\n",
    "\n",
    "# ElasticNet Regression\n",
    "elasticnet_params = {'model__alpha': [0.01, 0.1, 1.0], 'model__l1_ratio': [0.1, 0.5, 0.9]}\n",
    "elasticnet_model = GridSearchCV(ElasticNet(), elasticnet_params, cv=5)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "best_elasticnet_params = elasticnet_model.best_params_\n",
    "\n",
    "elasticnet_pred = elasticnet_model.predict(X_test)\n",
    "elasticnet_mae = mean_absolute_error(y_test, elasticnet_pred)\n",
    "elasticnet_mse = mean_squared_error(y_test, elasticnet_pred)\n",
    "print(f\"ElasticNet Performance:\\nBest Parameters: {best_elasticnet_params}\\nMean Absolute Error (MAE): {elasticnet_mae}\\nMean Squared Error (MSE): {elasticnet_mse}\")\n",
    "\n",
    "# XGBoost\n",
    "xgboost_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "xgboost_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "xgboost_search = GridSearchCV(xgboost_model, xgboost_params, cv=5)\n",
    "xgboost_search.fit(X_train, y_train)\n",
    "best_xgboost_params = xgboost_search.best_params_\n",
    "xgboost_pred = xgboost_search.predict(X_test)\n",
    "xgboost_mae = mean_absolute_error(y_test, xgboost_pred)\n",
    "xgboost_mse = mean_squared_error(y_test, xgboost_pred)\n",
    "print(f\"XGBoost Performance:\\nBest Parameters: {best_xgboost_params}\\nMean Absolute Error (MAE): {xgboost_mae}\\nMean Squared Error (MSE): {xgboost_mse}\")\n",
    "\n",
    "# Support Vector Regression (SVR)\n",
    "svr_model = SVR()\n",
    "svr_params = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': [1, 10],\n",
    "    'epsilon': [0.1]\n",
    "}\n",
    "# Use a smaller subset for tuning\n",
    "X_train_small, _, y_train_small, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=42)\n",
    "svr_search = GridSearchCV(svr_model, svr_params, cv=3, n_jobs=-1)\n",
    "svr_search.fit(X_train_small, y_train_small)\n",
    "best_svr_params = svr_search.best_params_\n",
    "svr_pred = svr_search.predict(X_test)\n",
    "svr_mae = mean_absolute_error(y_test, svr_pred)\n",
    "svr_mse = mean_squared_error(y_test, svr_pred)\n",
    "print(f\"SVR Performance:\\nBest Parameters: {best_svr_params}\\nMean Absolute Error (MAE): {svr_mae}\\nMean Squared Error (MSE): {svr_mse}\")\n",
    "\n",
    "# Artificial Neural Network (ANN)\n",
    "def build_ann_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    return model\n",
    "\n",
    "ann_model = KerasRegressor(build_fn=build_ann_model, epochs=100, batch_size=32, verbose=0)\n",
    "ann_model.fit(X_train, y_train)\n",
    "ann_pred = ann_model.predict(X_test)\n",
    "ann_mae = mean_absolute_error(y_test, ann_pred)\n",
    "ann_mse = mean_squared_error(y_test, ann_pred)\n",
    "print(f\"ANN Performance:\\nMean Absolute Error (MAE): {ann_mae}\\nMean Squared Error (MSE): {ann_mse}\")\n",
    "\n",
    "# Ensemble Model\n",
    "ensemble_model = VotingRegressor(estimators=[\n",
    "    ('ridge', ridge_model.best_estimator_),\n",
    "    ('lasso', lasso_model.best_estimator_),\n",
    "    ('elasticnet', elasticnet_model.best_estimator_),\n",
    "    ('xgboost', xgboost_search.best_estimator_)\n",
    "])\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "ensemble_pred = ensemble_model.predict(X_test)\n",
    "ensemble_mae = mean_absolute_error(y_test, ensemble_pred)\n",
    "ensemble_mse = mean_squared_error(y_test, ensemble_pred)\n",
    "print(f\"Ensemble Performance:\\nMean Absolute Error (MAE): {ensemble_mae}\\nMean Squared Error (MSE): {ensemble_mse}\")\n",
    "\n",
    "# Summary of Results\n",
    "results = {\n",
    "    'Model': ['Ridge', 'Lasso', 'ElasticNet', 'XGBoost', 'SVR', 'ANN', 'Ensemble'],\n",
    "    'MAE': [ridge_mae, lasso_mae, elasticnet_mae, xgboost_mae, svr_mae, ann_mae, ensemble_mae],\n",
    "    'MSE': [ridge_mse, lasso_mse, elasticnet_mse, xgboost_mse, svr_mse, ann_mse, ensemble_mse]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Plot actual vs predicted for each model\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(y_test, ridge_pred, color='blue', label='Ridge Predictions')\n",
    "plt.scatter(y_test, lasso_pred, color='green', label='Lasso Predictions')\n",
    "plt.scatter(y_test, elasticnet_pred, color='orange', label='ElasticNet Predictions')\n",
    "plt.scatter(y_test, xgboost_pred, color='purple', label='XGBoost Predictions')\n",
    "plt.scatter(y_test, svr_pred, color='cyan', label='SVR Predictions')\n",
    "plt.scatter(y_test, ann_pred, color='magenta', label='ANN Predictions')\n",
    "plt.scatter(y_test, ensemble_pred, color='red', label='Ensemble Predictions')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'black', linewidth=2)\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs Predicted SalePrice')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
